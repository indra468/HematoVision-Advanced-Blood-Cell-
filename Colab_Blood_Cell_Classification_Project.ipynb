{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indra468/CRT/blob/main/Colab_Blood_Cell_Classification_Project_ipynp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUKWChLOS7-O"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pm-ejOOJTa0O"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d paultimothymooney/blood-cells"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o blood-cells.zip"
      ],
      "metadata": {
        "id": "eyxYYUwJ6VMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the directory path\n",
        "data_dir = '/content/dataset2-master/dataset2-master/images/TRAIN'\n",
        "\n",
        "# Define the class labels with corrected casing\n",
        "class_labels = ['EOSINOPHIL', 'LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL']\n",
        "\n",
        "# Initialize lists to hold file paths and labels\n",
        "filepaths = []\n",
        "labels = []\n",
        "\n",
        "# Loop through each class directory and gather file paths and labels\n",
        "for label in class_labels:\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for file in os.listdir(class_dir):\n",
        "        if file.endswith('.jpeg') or file.endswith('.png'):  # Ensure file is an image\n",
        "            filepaths.append(os.path.join(class_dir, file))\n",
        "            labels.append(label)\n",
        "\n",
        "# Create a DataFrame from the file paths and labels\n",
        "bloodCell_df = pd.DataFrame({\n",
        "    'filepaths': filepaths,\n",
        "    'labels': labels\n",
        "})\n",
        "\n",
        "# Shuffle the DataFrame\n",
        "bloodCell_df = bloodCell_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Display first few rows\n",
        "print(bloodCell_df.head())"
      ],
      "metadata": {
        "id": "qKYxhNFAXL-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DH6xoBBI6g8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e169e70b"
      },
      "source": [
        "### Setup ImageDataGenerators and Display Sample Images\n",
        "\n",
        "This cell combines the setup of `ImageDataGenerator` for training and testing data with the `show_knee_images` function call, ensuring that `train_data` is properly defined before being used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02a98589"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_dir = \"/content/dataset2-master/dataset2-master/images/TRAIN\"\n",
        "test_dir = \"/content/dataset2-master/dataset2-master/images/TEST\"\n",
        "\n",
        "# Create an ImageDataGenerator for data loading and preprocessing\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load training data\n",
        "train_data = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load testing data\n",
        "test_data = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Function to display a grid of images from the generator\n",
        "def show_knee_images(image_gen):\n",
        "    test_dict = image_gen.class_indices\n",
        "    classes = list(test_dict.keys())\n",
        "\n",
        "    images, labels = next(image_gen)\n",
        "\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    length = len(labels)\n",
        "\n",
        "    if length < 25:\n",
        "        r = length\n",
        "    else:\n",
        "        r = 25\n",
        "\n",
        "    for i in range(r):\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        image = (images[i] + 1) / 2 # Adjust if images are already in [0,1]\n",
        "        plt.imshow(image)\n",
        "\n",
        "        index = np.argmax(labels[i])\n",
        "        class_name = classes[index]\n",
        "\n",
        "        plt.title(class_name, color=\"green\", fontsize=16)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to display images from the training data\n",
        "show_knee_images(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train and test\n",
        "train_images, test_images = train_test_split(\n",
        "    bloodCell_df,\n",
        "    test_size=0.3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Split training again into train and validation\n",
        "train_set, val_set = train_test_split(\n",
        "    bloodCell_df,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Print shapes\n",
        "print(train_set.shape)\n",
        "print(test_images.shape)\n",
        "print(val_set.shape)\n",
        "print(train_images.shape)\n"
      ],
      "metadata": {
        "id": "jQaWuCzfZT46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "\n",
        "# Image generator with MobileNetV2 preprocessing\n",
        "image_gen = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
        ")\n",
        "\n",
        "# Train generator\n",
        "train = image_gen.flow_from_dataframe(\n",
        "    dataframe=train_set,\n",
        "    x_col=\"filepaths\",\n",
        "    y_col=\"labels\",\n",
        "    target_size=(244, 244),\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=8,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Test generator\n",
        "test = image_gen.flow_from_dataframe(\n",
        "    dataframe=test_images,\n",
        "    x_col=\"filepaths\",\n",
        "    y_col=\"labels\",\n",
        "    target_size=(244, 244),\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=8,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "val = image_gen.flow_from_dataframe(\n",
        "    dataframe=val_set,\n",
        "    x_col=\"filepaths\",\n",
        "    y_col=\"labels\",\n",
        "    target_size=(244, 244),\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=8,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "yma3kbNEZgqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=128, kernel_size=(8, 8), strides=(3, 3),\n",
        "                        activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1),\n",
        "                        activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3, 3)),\n",
        "\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1),\n",
        "                        activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(1, 1), strides=(1, 1),\n",
        "                        activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(1, 1), strides=(1, 1),\n",
        "                        activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D(filters=512, kernel_size=(3, 3),\n",
        "                        activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "\n",
        "    keras.layers.Conv2D(filters=512, kernel_size=(3, 3),\n",
        "                        activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D(filters=512, kernel_size=(3, 3),\n",
        "                        activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "\n",
        "    keras.layers.Conv2D(filters=512, kernel_size=(3, 3),\n",
        "                        activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(1024, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(1024, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(4, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=tf.optimizers.SGD(learning_rate=0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "    train,\n",
        "    epochs=10,\n",
        "    validation_data=val\n",
        ")\n"
      ],
      "metadata": {
        "id": "Jk-0YpxKZxjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predictions\n",
        "pred = model.predict(test)\n",
        "pred = np.argmax(pred, axis=1)  # pick class with highest probability\n",
        "\n",
        "# Convert numeric labels to class names\n",
        "labels = train.class_indices\n",
        "labels = dict((v, k) for k, v in labels.items())\n",
        "pred2 = [labels[k] for k in pred]\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w69Dk-LXaNUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# True labels from test set\n",
        "y_test = test_images.labels  # expected output labels\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, pred2))\n",
        "\n",
        "# Overall accuracy\n",
        "print(\"Accuracy of the Model: {:.1f}%\".format(accuracy_score(y_test, pred2) * 100))\n"
      ],
      "metadata": {
        "id": "uhfWTU-kfJ-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Class labels\n",
        "class_labels = ['EOSINOPHIL', 'LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL']\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, pred2)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues')\n",
        "\n",
        "# Axis labels and ticks\n",
        "plt.xticks(ticks=[0.5, 1.5, 2.5, 3.5], labels=class_labels)\n",
        "plt.yticks(ticks=[0.5, 1.5, 2.5, 3.5], labels=class_labels)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "\n",
        "# Title\n",
        "plt.title(\"Confusion Matrix\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qpqeX9IXfbun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Blood Cell.h5\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"Blood Cell.h5\")\n"
      ],
      "metadata": {
        "id": "H1xvKDSgg8-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch gradio accelerate bitsandbytes diffusers torchvision"
      ],
      "metadata": {
        "id": "DoIAk8nTXJ-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import torch"
      ],
      "metadata": {
        "id": "FcXg2jzlIpRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load IBM Granite Model\n",
        "model_name = \"ibm-granite/granite-3.3-2b-instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "granite_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512\n",
        ")"
      ],
      "metadata": {
        "id": "N6980FV_IuSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Transfer Learning CNN MODEL\n",
        "model_cnn = models.resnet50(pretrained=True)\n",
        "model_cnn.fc = torch.nn.Linear(model_cnn.fc.in_features, 3)  # 3 classes: RBC, WBC, Platelet\n",
        "model_cnn.eval()\n",
        "# Image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "# Blood Cell Classes\n",
        "classes = [\n",
        "    \"microscopic image of human blood smear with eosinophil, lymphocyte, monocyte, and neutrophil blood cells, high detail\"\n",
        "]\n",
        "\n",
        "# Classification Function\n",
        "def classify_image(img):\n",
        "\n",
        "    image = transform(img).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model_cnn(image)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    return classes[predicted.item()]"
      ],
      "metadata": {
        "id": "ynTb7dQAI0c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_report(cell_type):\n",
        "\n",
        "    prompt = f\"Explain the characteristics and clinical significance of a {cell_type}.\"\n",
        "\n",
        "    response = granite_pipeline(prompt)[0]['generated_text']\n",
        "\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "jiLF6kZpfJZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4GOldy-U6tE"
      },
      "source": [
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import gc\n",
        "import logging\n",
        "\n",
        "# Configure logging for better visibility\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# --- Step 1: Clear existing models from GPU (if any) and Python memory ---\n",
        "logging.info(\"Starting aggressive memory cleanup...\")\n",
        "\n",
        "# Delete IBM Granite components if they exist globally\n",
        "if 'granite_model' in globals() and granite_model is not None and hasattr(granite_model, 'to'):\n",
        "    logging.info(f\"Moving existing granite_model to CPU from {granite_model.device} before deletion...\")\n",
        "    try:\n",
        "        granite_model.to('cpu')\n",
        "        del granite_model\n",
        "        logging.info(\"granite_model deleted.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error moving/deleting granite_model: {e}\")\n",
        "\n",
        "if 'granite_tokenizer' in globals() and granite_tokenizer is not None:\n",
        "    try:\n",
        "        del granite_tokenizer\n",
        "        logging.info(\"granite_tokenizer deleted.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error deleting granite_tokenizer: {e}\")\n",
        "\n",
        "if 'granite_pipeline' in globals() and granite_pipeline is not None:\n",
        "    try:\n",
        "        del granite_pipeline\n",
        "        logging.info(\"granite_pipeline deleted.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error deleting granite_pipeline: {e}\")\n",
        "\n",
        "# Delete the separate PyTorch model_cnn if it exists globally (from ynTb7dQAI0c6)\n",
        "# Note: model_cnn is a Keras model, it doesn't have a '.device' attribute or '.to()' method like PyTorch models.\n",
        "# Simply deleting the variable will release its resources.\n",
        "if 'model_cnn' in globals() and model_cnn is not None:\n",
        "    logging.info(\"Deleting model_cnn (Keras ResNet50)...\")\n",
        "    try:\n",
        "        del model_cnn\n",
        "        logging.info(\"model_cnn (Keras ResNet50) deleted.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error deleting model_cnn: {e}\")\n",
        "\n",
        "# Delete the previously loaded Stable Diffusion pipe if it exists globally\n",
        "if 'pipe' in globals() and pipe is not None and hasattr(pipe, 'to'):\n",
        "    logging.info(f\"Moving existing Stable Diffusion pipe to CPU from {pipe.device} before deletion...\")\n",
        "    try:\n",
        "        pipe.to('cpu')\n",
        "        del pipe\n",
        "        logging.info(\"Stable Diffusion pipe deleted.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error moving/deleting Stable Diffusion pipe: {e}\")\n",
        "\n",
        "# Force garbage collection and clear CUDA cache\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "logging.info(\"Aggressive memory cleanup completed: Garbage collected and CUDA cache emptied.\")\n",
        "\n",
        "\n",
        "# --- Step 2: Load Keras Classification Model on CPU ---\n",
        "logging.info(\"Loading Keras classification model on CPU...\")\n",
        "classification_model = None\n",
        "try:\n",
        "    classification_model = keras.models.load_model(\"Blood Cell.h5\")\n",
        "    logging.info(\"Keras classification model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error loading Keras classification model: {e}\")\n",
        "\n",
        "# Define class labels corresponding to the model's output\n",
        "class_labels = ['EOSINOPHIL', 'LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL']\n",
        "\n",
        "# Image preprocessing for the Keras model\n",
        "def preprocess_image_for_classification(image: Image.Image):\n",
        "    if classification_model is None:\n",
        "        return None # Indicate that model is not available\n",
        "    image = image.resize((224, 224))  # Resize to model's expected input\n",
        "    image = np.array(image).astype('float32') / 255.0 # Convert to numpy array and normalize\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    return image\n",
        "\n",
        "logging.info(\"Keras classification model loading and preprocessing function defined.\")\n",
        "\n",
        "\n",
        "# --- Step 3: Load Text Generation Model on CPU ---\n",
        "logging.info(\"Loading IBM Granite text generation model on CPU...\")\n",
        "granite_model_loaded = False\n",
        "granite_pipeline = None\n",
        "try:\n",
        "    granite_tokenizer = AutoTokenizer.from_pretrained(model_name_granite)\n",
        "    granite_model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name_granite,\n",
        "        torch_dtype=torch.float32,\n",
        "        device_map=\"cpu\"\n",
        "    )\n",
        "    granite_pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=granite_model,\n",
        "        tokenizer=granite_tokenizer,\n",
        "        max_new_tokens=512\n",
        "    )\n",
        "    granite_model_loaded = True\n",
        "    logging.info(\"IBM Granite text generation model loaded on CPU successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error loading IBM Granite text generation model on CPU: {e}\")\n",
        "\n",
        "# Function to generate report\n",
        "def generate_report(cell_type):\n",
        "    if not granite_model_loaded or granite_pipeline is None:\n",
        "        return \"AI Report generation is currently unavailable due to model loading issues.\" # Fallback if model failed to load\n",
        "    prompt = f\"Explain the characteristics and clinical significance of a {cell_type}.\"\n",
        "    try:\n",
        "        output = granite_pipeline(prompt)\n",
        "        if output and isinstance(output, list) and len(output) > 0 and 'generated_text' in output[0]:\n",
        "            return output[0]['generated_text']\n",
        "        else:\n",
        "            logging.warning(f\"granite_pipeline output unexpected: {output}\")\n",
        "            return \"Could not generate report due to unexpected pipeline output.\"\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during AI report generation: {e}\")\n",
        "        return \"Error occurred during AI report generation.\"\n",
        "\n",
        "\n",
        "# --- Step 4: Stable Diffusion Setup ---\n",
        "logging.info(\"Loading Stable Diffusion pipeline...\")\n",
        "stable_diffusion_loaded = False\n",
        "pipe = None\n",
        "try:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    sd_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        torch_dtype=sd_dtype,\n",
        "        low_cpu_mem_usage=True\n",
        "    )\n",
        "    pipe.enable_attention_slicing()\n",
        "    pipe.enable_model_cpu_offload()\n",
        "    stable_diffusion_loaded = True\n",
        "    logging.info(\"Stable Diffusion pipeline loaded and configured successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error loading Stable Diffusion pipeline: {e}\")\n",
        "\n",
        "# Function to generate blood smear image\n",
        "def generate_blood_smear_image():\n",
        "    if not stable_diffusion_loaded or pipe is None:\n",
        "        logging.warning(\"Stable Diffusion model not loaded. Cannot generate image.\")\n",
        "        return Image.new('RGB', (224, 224), color = 'red') # Placeholder red image\n",
        "    prompt = \"microscopic image of human blood smear with eosinophil, lymphocyte, monocyte, and neutrophil blood cells, high detail\"\n",
        "    try:\n",
        "        generated_image = pipe(prompt).images[0]\n",
        "        return generated_image\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error generating blood smear image: {e}\")\n",
        "        return Image.new('RGB', (224, 224), color = 'red') # Placeholder for generation error\n",
        "\n",
        "\n",
        "# --- Step 5: Define Combined Gradio Prediction Function ---\n",
        "def process_blood_image(input_image: Image.Image):\n",
        "    # 1. Classify the uploaded image\n",
        "    classification_result = \"Classification unavailable: Model not loaded or errored.\"\n",
        "    if classification_model is not None:\n",
        "        processed_image = preprocess_image_for_classification(input_image)\n",
        "        if processed_image is not None:\n",
        "            try:\n",
        "                predictions = classification_model.predict(processed_image)\n",
        "                predicted_class_idx = np.argmax(predictions, axis=1)[0]\n",
        "                confidence = np.max(predictions)\n",
        "                predicted_class_name = class_labels[predicted_class_idx]\n",
        "                classification_result = f\"Class: {predicted_class_name}, Confidence: {confidence:.2f}\"\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error during classification prediction: {e}\")\n",
        "                classification_result = f\"Classification error: {e}\"\n",
        "        else:\n",
        "            classification_result = \"Classification unavailable: Image preprocessing failed.\"\n",
        "\n",
        "\n",
        "    # 2. Generate an AI report based on the classification\n",
        "    # Use a generic prompt if classification failed or model not loaded\n",
        "    ai_report_cell_type = locals().get('predicted_class_name', 'blood cell')\n",
        "    ai_report = generate_report(ai_report_cell_type)\n",
        "\n",
        "\n",
        "    # 3. Generate a synthetic blood smear image\n",
        "    synthetic_image = generate_blood_smear_image()\n",
        "\n",
        "    return classification_result, ai_report, synthetic_image\n",
        "\n",
        "\n",
        "# --- Step 6: Create Gradio Interface ---\n",
        "logging.info(\"Building Gradio Interface...\")\n",
        "with gr.Blocks() as demo_combined:\n",
        "    gr.Markdown(\"# ðŸ©¸ Blood Cell Analysis and Synthesis ðŸ§¬\")\n",
        "    gr.Markdown(\"Upload a blood cell image for classification, get an AI-generated report, and see a synthetic blood smear image.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            input_image_comp = gr.Image(type=\"pil\", label=\"Upload Blood Cell Image\")\n",
        "            process_button = gr.Button(\"Analyze & Generate\")\n",
        "        with gr.Column():\n",
        "            classification_output = gr.Label(label=\"Classification Result\")\n",
        "            report_output = gr.Textbox(label=\"AI-Generated Report\", lines=10)\n",
        "            synthetic_image_output = gr.Image(type=\"pil\", label=\"Synthetic Blood Smear Image\")\n",
        "\n",
        "    process_button.click(\n",
        "        fn=process_blood_image,\n",
        "        inputs=[input_image_comp],\n",
        "        outputs=[classification_output, report_output, synthetic_image_output]\n",
        "    )\n",
        "\n",
        "    # Use queue() to allow multiple requests and better handle long inference times\n",
        "    # This is especially important for models like Stable Diffusion and large LLMs.\n",
        "    demo_combined.queue()\n",
        "\n",
        "demo_combined.launch(share=True)\n",
        "logging.info(\"Gradio Interface launched.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
